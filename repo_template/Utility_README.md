# Expected repository structure of a problem

For each new problem a separate repository in the [Turing Alibaba CP organization](https://github.com/Dragon-POC/) should be created, please use lowercase + underscore naming convention for repository names, i.e. `collapsed_tree_shadows`.

```
├── qwen/                    # Qwen's solution attempts
│   ├── prompt.txt           # Prompt used to interact with the model
│   ├── run_01.cpp           # Qwen's solution attempt 1
│   ├── run_02.cpp           # Qwen's solution attempt 2
│   ├── ...                  # ...
│   └── run_16.cpp           # Qwen's solution attempt 16
├── test_cases/              # Test cases directory
│   ├── 1.in                # Generated test cases
│   ├── 1.out               # Generated test cases expected outputs
│   ├── ...
│   ├── example_1.in         # Examples provided with the prompt
│   ├── example_1.out        # Outputs for examples provided with the prompt
│   ├── ...
│   ├── test_1.in            # Initial/manual test cases
│   ├── test_1.out           # Expected outputs for manual test cases
│   ├── ...
│   ├── test_edge_1.in       # Edge case tests (manually created)
│   ├── test_edge_1.out      # Edge case expected outputs
│   └── ...
├── idea.md                  # Description how the problem was created
├── README.md                # Project documentation
├── problem_statement.md     # Problem statement and requirements
├── requirements.json        # Metadata to generate final delivery
├── test_generator.cpp       # (optional) Test generator
├── solution.md              # Explanation of the optimal solution
├── standard.cpp             # Correct (optimal) implementation
└── standard_2.cpp           # (optional) Another correct (optimal) implementation
```

See [collapsed_tree_shadows](https://github.com/Dragon-POC/collapsed_tree_shadows) repository as an example.

## Problem Statement, Idea and Solution Explanation

- `idea.md`: Documents the problem's origin and development process, including how the problem was conceived and any references to existing problems it was derived from.
   - This should be a MANUALLY written description of your thought process and interaction with different models , i.e.:
      1. I know algorithm XXX well, so I decided to create a task around this algorithm.
      2. I asked ChatGPT o3 to propose some formulations and selected one of them.
      3. I asked  ChatGPT 4o to generate some tests.
      4. I tested on Qwen, it passed.
      5. I asked ChatGPT o4-mini-high to change some limits.
      6. ...
   - This file will help us to understand you way of thinking and interaction with the models. Later we can build an agent which will automate most parts of the process.
- `prompt.md`: Detailed problem statement including:
   - Input/output format
   - Constraints
   - Examples with explanations
- `solution.md`: Detailed solution explanation
   - Explans the code and approach used in `standard*.cpp` files.


## Solutions

### Reference implementations

- `standard.cpp` - reference solution that passes all test cases
   - Main optimized solution that passes all test cases
   - Uses efficient data structures and algorithms to meet time/memory constraints
- `standard_xxx.cpp` - (optional) additional reference solutions

### Other Implementations

You can add other implementations which can help you to develop and debug the problem:
- `solution_bf.cpp` - Brute Force Solution
   - Used as a reference implementation to generate test outputs
   - Implements a straightforward approach without optimizations
   - Guaranteed to produce correct results but may be slow for large inputs
   - Useful for:
      - Validating test cases
      - Debugging optimized solutions
      - Understanding the basic algorithm

Only `standard*.cpp` solutions will go to the final delivery, other `.cpp` files are ignored.

## Qwen Prompt and Solutions

The qwen directory contains a collection of solutions generated by the Qwen model that fail on various test cases. These solutions should be collected by feeding the prompt from prompt.md to the Qwen3-235B-A22B model with **thinking enabled**. There should be 16 solutions collected which fail the test suite.

`prompt.txt` contains the problem statement (the same as `problem_statement.md`) + some instructions how to generate the final solution, i.e. "Solve using C++.".


## Test files structure (`test_cases` folder)
The `test_cases` directory contains all test cases and their expected outputs. Each test case consists of two files:
   - `.in` file: Contains the test input
   - `.out` file: Contains the expected output

The files follow these naming conventions:
- **Generated Tests** - files named `1.in/out`, `2.in/out`. This file should be generated by a single run test generator provided in the repository.
- **Example Tests**
   - `example_1.in`: Example input from the problem statement
   - `example_1.out`: Expected output for the example
   - Multiple examples may be provided in the problem statement
- **Basic Tests** - these tests are manually crafted during the initial problem development phase to establish baseline functionality and edge cases
   - `test_1.in`, `test_2.in`, etc.: Basic test cases
   - `test_1.out`, `test_2.out`, etc.: Expected outputs
- **Edge Case Tests** - files named `test_edge_1_description.in/out` where:
   - (optional) description: brief description of what the test case checks
   - Edge case tests are designed to challenge solutions with extreme or boundary conditions that might expose bugs in the implementation
   - Examples:
      - `test_edge_1_min_tree.in`: Tests minimum possible tree
      - `test_edge_2_single_edge.in`: Tests tree with single edge
      - `test_edge_3_deep_stick.in`: Tests deep linear tree
      - `test_edge_4_large_balanced.in`: Tests large balanced tree


## Test case generator

`test_generator.cpp`, or other file/script, should follow these conventions:
1. When run without arguments (i.e., `./test_generator`), it should generate test cases in the `test_cases` folder with sequential naming:
   - Input files: `1.in`, `2.in`, `3.in`, etc.
   - Output files: `1.out`, `2.out`, `3.out`, etc.
2. If generated test cases already exist in the `test_cases` folder, continue the sequential numbering (e.g., if `1.in/out` and `2.in/out` exist, start with `3.in/out`).
3. The number of generated test cases by a single run of the test generator must match the number of existing `test_cases/xx.in/out` files in the repository.
4. Note: The `test_cases/xx.in/out` files saved in the repository are pre-generated test cases which serve as a golden sample of generated test cases.
5. Important: In the final delivery:
   - All test case files (manual and generated) will be renamed sequentially as `1.in/out`, `2.in/out`, etc.
   - Manual test cases will be numbered first, followed by generated test cases
6. You may use any other approach to generate test cases, for example, Python scripts. In this case, leave the `test_case_generator` field empty in `requirements.json`, but still name the generated test cases as `test_gen_xx.in/out`.


## Metadata

`requirements.json` defines metadata which is used to generate the final delivery.

`requirements.json` structure (all fields are obligatory and should have exact same naming):
```
{
    "title": "Collapsed Tree Shadows",
    "original": "",
    "difficulty": "Hard",
    "tags": [
        "DS/Tree",
        "DS/BinaryIndexedTree",
        "DS/IntervalTree",
        "DS/SegmentTree",
        "Algo/CoordinateCompression",
        "Algo/IntervalOperations",
        "Math/AffineTransformations"
    ],
    "time": 5,
    "space": 32,
    "problem_statement": "problem_statement.md",
    "standard_program": ["standard.cpp"],
    "explanation": "solution.md",
    "test_case_generator": "test_generator.cpp"
}
```

# Testing Utilities

The [utilities](https://github.com/Dragon-POC/utilities) repository contains `test_run.sh` and `delivery_gen.py` to test the problem repository and create final delivery. It is required to use this script to verify that the task conforms to all requirements.

Before running the scripts, ensure you have the following tools installed:
- **g++**: C++ compiler for building solutions
- **jq**: JSON processor for parsing and manipulating JSON data
- **gtime** (GNU time): For measuring execution time
- **timeout** (coreutils): For enforcing time limits on test execution

Installation on macOS: `brew install coreutils gnu-time jq`

## test_run.sh

A script for testing solutions against test cases. It supports both original problem repositories and delivery packages.

### Usage

```bash
# Test all solutions in a directory (works with both original and delivery formats)
./test_run.sh path/to/problem_dir

# Test a specific solution
./test_run.sh path/to/problem_dir --solution path/to/solution.cpp

# Run all test cases even if solution fails on some tests
./test_run.sh --full path/to/problem_dir

# Run all test cases for a specific solution
./test_run.sh --full path/to/problem_dir --solution path/to/solution.cpp
```

### Features

1. Tests both optimal and Qwen-generated solutions
2. Creates logs in `logs/<problem_dir_name>/` directory
3. Supports two ways to specify optimal solutions:
   - Via `standard_program` array in`requirements.json/problem.json`
   - By matching `standard*.cpp` files if no array specified
4. Automatically detects test cases in either:
   - Original format: `tests/` directory
   - Delivery format: `test_cases/` directory
5. Automatically detects Qwen solutions in either:
   - Original format: `qwen/solution_XX.cpp`
   - Delivery format: `QwenTest/run_XX.cpp`
6. Supports two testing modes:
   - Default mode: stops testing at first failure
   - Full test mode (--full flag): runs all test cases regardless of failures

### Example Outputs

#### Testing Original Problem Repository (Default Mode)

```bash
$ ./test_run.sh ../test_gen_steady_mincost
Testing all solutions in qwen folder...
Detailed logs will be saved in logs/test_gen_steady_mincost directory

Testing optimal solutions from requirements.json...
Testing optimal solution solution_correct.cpp... done: 77 passed / 0 failed / 0 crashed / 77 total.

Optimal Solutions Summary:
Solutions: 1 passed / 0 failed from 1 total

Testing Qwen solutions...
Testing solution_01.cpp... done: 0 passed / 1 failed / 0 crashed / 1 total.
Testing solution_02.cpp... done: 13 passed / 1 failed / 0 crashed / 14 total.
...
Testing solution_16.cpp... done: 0 passed / 1 failed / 0 crashed / 1 total.

Qwen Solutions Summary:
Solutions: 0 passed / 16 failed from 16 total

Individual test logs are available in logs/test_gen_steady_mincost directory
```

#### Testing Original Problem Repository (Full Test Mode)

```bash
$ ./test_run.sh --full ../test_gen_steady_mincost
Testing all solutions in qwen folder...
Detailed logs will be saved in logs/test_gen_steady_mincost directory

Testing optimal solutions from requirements.json...
Testing optimal solution solution_correct.cpp... done: 77 passed / 0 failed / 0 crashed / 77 total.

Optimal Solutions Summary:
Solutions: 1 passed / 0 failed from 1 total

Testing Qwen solutions...
Testing solution_01.cpp... done: 0 passed / 40 failed / 37 crashed / 77 total.
Testing solution_02.cpp... done: 13 passed / 64 failed / 0 crashed / 77 total.
...
Testing solution_16.cpp... done: 0 passed / 77 failed / 0 crashed / 77 total.

Qwen Solutions Summary:
Solutions: 0 passed / 16 failed from 16 total

Individual test logs are available in logs/test_gen_steady_mincost directory
```

#### Testing Delivery Package

```bash
$ ./test_run.sh delivery/steady_walk_mincost
Testing all solutions in QwenTest folder...
Detailed logs will be saved in logs/steady_walk_mincost directory

No standard_program specified in problem.json, testing all standard*.cpp files...
Testing standard solution standard.cpp... done: 77 passed / 0 failed / 0 crashed / 77 total.

Optimal Solutions Summary:
Solutions: 1 passed / 0 failed from 1 total

Testing Qwen solutions...
Testing run_01.cpp... done: 0 passed / 40 failed / 37 crashed / 77 total.
Testing run_02.cpp... done: 13 passed / 64 failed / 0 crashed / 77 total.
...
Testing run_16.cpp... done: 0 passed / 77 failed / 0 crashed / 77 total.

Qwen Solutions Summary:
Solutions: 0 passed / 16 failed from 16 total

Individual test logs are available in logs/steady_walk_mincost directory
```

#### Testing Single Solution

```bash
$ ./test_run.sh ../test_gen_steady_mincost --solution qwen/solution_01.cpp
Running test cases (stopping at first failure) with time=4s, space=512MB...

example_01: CRASH (0.00s, 1.29MB)

Performance log: logs/test_gen_steady_mincost/solution_01-performance.json
Test Summary (solution_01.cpp): 0 passed / 0 failed / 1 crashed / 1 total.
```

```bash
$ ./test_run.sh --full ../test_gen_steady_mincost --solution qwen/solution_01.cpp
Running test cases (full test mode) with time=4s, space=512MB...

example_01: CRASH (0.00s, 1.29MB)
test_00: CRASH (0.00s, 1.23MB)
test_01: CRASH (0.00s, 1.23MB)
test_02: FAIL (0.00s, 1.23MB)
...
test_75: CRASH (0.00s, 1.23MB)

Performance log: logs/test_gen_steady_mincost/solution_01-performance.json
Test Summary (solution_01.cpp): 0 passed / 40 failed / 37 crashed / 77 total.
```

### Log Files

For each tested solution, the script creates:
- `logs/<problem_dir>/<solution>-performance.json`: Detailed performance metrics
- `logs/<problem_dir>/<solution>-log.txt`: Test run log when testing in batch mode


## delivery_gen.py

A script for creating delivery packages from problem repositories. It converts the original problem structure into a standardized delivery format.

### Usage

```bash
# Create delivery package from current directory
python delivery_gen.py

# Create delivery package from specific problem directory
python delivery_gen.py path/to/problem_dir

# Create delivery package with custom problem ID
python delivery_gen.py path/to/problem_dir --problem-id custom_name

# Specify custom output directory (default: ./delivery/problem_dir_name)
python delivery_gen.py path/to/problem_dir --delivery-dir path/to/output
```

### Features

1. Creates standardized delivery structure:
   ```
   <problem-id>/
   ├── problem.json         # Problem metadata and statement
   ├── QwenTest/           # Qwen's solution attempts
   │   ├── prompt.txt      # Original prompt
   │   ├── run_01.cpp      # Renamed from solution_01.cpp
   │   └── ...
   ├── test_cases/         # All test cases, sequentially numbered
   │   ├── 1.in           # First test case (example)
   │   ├── 1.out
   │   ├── 2.in           # Regular test cases
   │   └── ...
   ├── standard.cpp        # Main correct solution
   └── solution.md         # Solution explanation
   ```
2. By default, creates delivery package in `./delivery/<problem_dir_name>/`
3. Automatically converts and renames test cases sequentially
4. Copies and renames Qwen solutions from `solution_XX.cpp` to `run_XX.cpp`
5. Creates `problem.json` with metadata from `requirements.json`
6. Preserves solution explanation and standard solution

### Example Output

```bash
$ python delivery_gen.py ../test_gen_steady_mincost
Created new directory: delivery/test_gen_steady_mincost
Reading requirements from: .../test_gen_steady_mincost/requirements.json
Reading statement from: .../test_gen_steady_mincost/prompt.md
Found 1 example_*.in cases in .../test_gen_steady_mincost/tests
Writing problem.json to: delivery/test_gen_steady_mincost/problem.json
Copied test case example_01.in -> 1.in
Copied test case test_00.in -> 2.in
Copied test case test_01.in -> 3.in
...
Copied test case test_74.in -> 76.in
Copied test case test_75.in -> 77.in
Total test cases copied: 77
Copied main solution from solution_correct.cpp to standard.cpp
Copied solution explanation from solution.md

✅ Successfully created delivery package
   Output directory: delivery/test_gen_steady_mincost
```

## create_full_delivery.py

A script for creating a full delivery package containing multiple problems. It automates the process of cloning/updating repositories and generating delivery packages for each problem.

### Usage

```bash
# Create delivery package using default repo list (repo_list.txt)
./create_full_delivery.py

# Use a custom repository list file
./create_full_delivery.py --repo-list path/to/repo_list.txt
```

### Features

1. **Repository Management**:
   - Clones new repositories or updates existing ones
   - Efficiently checks if updates are needed before performing heavy git operations
   - Uses SSH protocol for git operations (automatically converts HTTPS URLs)

2. **Delivery Package Generation**:
   - Creates a timestamped delivery folder (e.g., `delivery_2025_07_08`)
   - Generates delivery packages for each repository using `delivery_gen.py`
   - Creates a final zip archive containing all problem packages

3. **Error Handling**:
   - Fails fast on any error (missing test cases, invalid repository, etc.)
   - Ensures all problems are properly packaged before creating the final archive

### Repository List Format

Create a `repo_list.txt` file with GitHub repository URLs (one per line):
```
# Lines starting with # are ignored
# Both HTTPS and Git protocol URLs are supported

https://github.com/Dragon-POC/Problem1
https://github.com/Dragon-POC/Problem2
```

### Directory Structure

The script creates and uses the following directory structure:
```
utilities/
├── repos/                  # Cloned repositories
├── delivery_YYYY_MM_DD/    # Generated delivery packages
└── delivery_YYYY_MM_DD.zip # Final zip archive
```
